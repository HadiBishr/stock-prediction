{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "22be10ad-4658-4c59-a30b-ad7824f32574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "983faa39-1f57-46b9-921e-76aeafbc668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "APIKEY = 'RFb2_XmabVtkYj4SFsIdl8oZFc0ApE5F'\n",
    "symbol = 'AMZN'\n",
    "date_start_train = '2023-01-01'\n",
    "date_end_train = '2023-07-01'\n",
    "date_start_val = '2023-07-02'\n",
    "date_end_val = '2024-01-01'\n",
    "date_start_test = '2024-01-02'\n",
    "date_end_test = '2024-06-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cfce7b37-62f5-4a5a-9ea8-d10f0710c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_train = f'https://api.polygon.io/v2/aggs/ticker/{symbol}/range/1/day/{date_start_train}/{date_end_train}?adjusted=true&sort=asc&apiKey={APIKEY}'\n",
    "url_val = f'https://api.polygon.io/v2/aggs/ticker/{symbol}/range/1/day/{date_start_val}/{date_end_val}?adjusted=true&sort=asc&apiKey={APIKEY}'\n",
    "\n",
    "response_train = requests.get(url_train)\n",
    "response_val = requests.get(url_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b4cc6e04-3630-4c8f-863b-a8232c34a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this 1 minuet after the cell above because I am using the free subscription.\n",
    "\n",
    "url_test = f'https://api.polygon.io/v2/aggs/ticker/{symbol}/range/1/day/{date_start_test}/{date_end_test}?adjusted=true&sort=asc&apiKey={APIKEY}'\n",
    "response_test = requests.get(url_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "713a2a7a-3fca-421e-8ae0-72ec01cd79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if response_train.status_code == 200:\n",
    "    data = response_train.json()\n",
    "    stock_data_train = data['results']\n",
    "    data = response_val.json()\n",
    "    stock_data_val = data['results']\n",
    "    data = response_test.json()\n",
    "    stock_data_test = data['results']\n",
    "else:\n",
    "    print(f'Error: {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1dc3263e-b39f-4d69-bd78-38903f082b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'v': 47314924.0, 'vw': 149.8529, 'o': 151.54, 'c': 149.93, 'h': 152.38, 'l': 148.39, 't': 1704171600000, 'n': 476432}, {'v': 49410095.0, 'vw': 149.4055, 'o': 149.2, 'c': 148.47, 'h': 151.05, 'l': 148.33, 't': 1704258000000, 'n': 416954}, {'v': 56039807.0, 'vw': 145.416, 'o': 145.59, 'c': 144.57, 'h': 147.38, 'l': 144.05, 't': 1704344400000, 'n': 541342}, {'v': 45003147.0, 'vw': 145.4485, 'o': 144.69, 'c': 145.24, 'h': 146.59, 'l': 144.53, 't': 1704430800000, 'n': 380385}, {'v': 46757053.0, 'vw': 148.3238, 'o': 146.74, 'c': 149.1, 'h': 149.4, 'l': 146.15, 't': 1704690000000, 'n': 410733}, {'v': 43812567.0, 'vw': 150.6311, 'o': 148.33, 'c': 151.37, 'h': 151.71, 'l': 148.21, 't': 1704776400000, 'n': 403026}, {'v': 44421830.0, 'vw': 153.4523, 'o': 152.06, 'c': 153.73, 'h': 154.42, 'l': 151.881, 't': 1704862800000, 'n': 430517}, {'v': 49072691.0, 'vw': 155.0181, 'o': 155.04, 'c': 155.18, 'h': 157.17, 'l': 153.12, 't': 1704949200000, 'n': 468131}, {'v': 40455355.0, 'vw': 154.8237, 'o': 155.39, 'c': 154.62, 'h': 156.2, 'l': 154.01, 't': 1705035600000, 'n': 351913}, {'v': 41360986.0, 'vw': 153.1344, 'o': 153.53, 'c': 153.16, 'h': 154.99, 'l': 152.15, 't': 1705381200000, 'n': 396069}, {'v': 34953363.0, 'vw': 151.2287, 'o': 151.49, 'c': 151.71, 'h': 152.15, 'l': 149.91, 't': 1705467600000, 'n': 354674}, {'v': 37850245.0, 'vw': 153.1334, 'o': 152.77, 'c': 153.5, 'h': 153.775, 'l': 151.82, 't': 1705554000000, 'n': 344845}, {'v': 51621628.0, 'vw': 154.6116, 'o': 153.83, 'c': 155.34, 'h': 155.76, 'l': 152.74, 't': 1705640400000, 'n': 408184}, {'v': 43687468.0, 'vw': 154.9418, 'o': 156.89, 'c': 154.78, 'h': 157.05, 'l': 153.9, 't': 1705899600000, 'n': 427992}, {'v': 37986039.0, 'vw': 155.3239, 'o': 154.85, 'c': 156.02, 'h': 156.21, 'l': 153.93, 't': 1705986000000, 'n': 353578}, {'v': 48403865.0, 'vw': 157.4001, 'o': 157.8, 'c': 156.87, 'h': 158.51, 'l': 156.48, 't': 1706072400000, 'n': 435420}, {'v': 43626052.0, 'vw': 157.1522, 'o': 156.95, 'c': 157.75, 'h': 158.505, 'l': 154.5501, 't': 1706158800000, 'n': 455333}, {'v': 49312353.0, 'vw': 159.1859, 'o': 158.42, 'c': 159.12, 'h': 160.72, 'l': 157.91, 't': 1706245200000, 'n': 426673}, {'v': 45270385.0, 'vw': 160.2769, 'o': 159.34, 'c': 161.26, 'h': 161.29, 'l': 158.9, 't': 1706504400000, 'n': 447373}, {'v': 45198365.0, 'vw': 159.4988, 'o': 160.7, 'c': 159, 'h': 161.73, 'l': 158.49, 't': 1706590800000, 'n': 458713}, {'v': 50155866.0, 'vw': 156.2675, 'o': 157, 'c': 155.2, 'h': 159.01, 'l': 154.81, 't': 1706677200000, 'n': 532780}, {'v': 76222119.0, 'vw': 160.6995, 'o': 155.87, 'c': 159.28, 'h': 159.76, 'l': 155.62, 't': 1706763600000, 'n': 742977}, {'v': 117018313.0, 'vw': 170.9334, 'o': 169.19, 'c': 171.81, 'h': 172.5, 'l': 167.33, 't': 1706850000000, 'n': 1134750}, {'v': 54876149.0, 'vw': 169.5257, 'o': 170.2, 'c': 170.31, 'h': 170.55, 'l': 167.7, 't': 1707109200000, 'n': 572534}, {'v': 42505518.0, 'vw': 168.8813, 'o': 169.39, 'c': 169.15, 'h': 170.71, 'l': 167.65, 't': 1707195600000, 'n': 406692}, {'v': 47171760.0, 'vw': 170.181, 'o': 169.48, 'c': 170.53, 'h': 170.88, 'l': 168.94, 't': 1707282000000, 'n': 452956}, {'v': 42309954.0, 'vw': 170.2667, 'o': 169.65, 'c': 169.84, 'h': 171.43, 'l': 168.88, 't': 1707368400000, 'n': 399951}, {'v': 56985986.0, 'vw': 173.3948, 'o': 170.9, 'c': 174.45, 'h': 175, 'l': 170.5803, 't': 1707454800000, 'n': 549269}, {'v': 50922340.0, 'vw': 173.2976, 'o': 174.8, 'c': 172.34, 'h': 175.39, 'l': 171.54, 't': 1707714000000, 'n': 512027}, {'v': 56289922.0, 'vw': 168.877, 'o': 167.73, 'c': 168.64, 'h': 170.95, 'l': 165.75, 't': 1707800400000, 'n': 572687}, {'v': 42797544.0, 'vw': 170.0337, 'o': 169.21, 'c': 170.98, 'h': 171.21, 'l': 168.28, 't': 1707886800000, 'n': 457092}, {'v': 49844196.0, 'vw': 169.4354, 'o': 170.58, 'c': 169.8, 'h': 171.17, 'l': 167.59, 't': 1707973200000, 'n': 521439}, {'v': 48097744.0, 'vw': 169.1822, 'o': 168.74, 'c': 169.51, 'h': 170.42, 'l': 167.17, 't': 1708059600000, 'n': 468194}, {'v': 41978976.0, 'vw': 166.9099, 'o': 167.83, 'c': 167.08, 'h': 168.71, 'l': 165.74, 't': 1708405200000, 'n': 478319}, {'v': 44137123.0, 'vw': 168.5492, 'o': 168.94, 'c': 168.59, 'h': 170.23, 'l': 167.14, 't': 1708491600000, 'n': 466025}, {'v': 55392354.0, 'vw': 173.5407, 'o': 173.1, 'c': 174.58, 'h': 174.8, 'l': 171.77, 't': 1708578000000, 'n': 547144}, {'v': 59715243.0, 'vw': 174.7441, 'o': 174.28, 'c': 174.99, 'h': 175.75, 'l': 173.7, 't': 1708664400000, 'n': 467172}, {'v': 44368614.0, 'vw': 174.9955, 'o': 175.7, 'c': 174.73, 'h': 176.37, 'l': 174.26, 't': 1708923600000, 'n': 428536}, {'v': 31141732.0, 'vw': 173.7541, 'o': 174.075, 'c': 173.54, 'h': 174.62, 'l': 172.86, 't': 1709010000000, 'n': 357527}, {'v': 28180482.0, 'vw': 173.319, 'o': 172.44, 'c': 173.16, 'h': 174.05, 'l': 172.27, 't': 1709096400000, 'n': 328701}, {'v': 53805359.0, 'vw': 175.7037, 'o': 173.01, 'c': 176.76, 'h': 177.22, 'l': 172.85, 't': 1709182800000, 'n': 446966}, {'v': 31966152.0, 'vw': 177.8613, 'o': 176.75, 'c': 178.22, 'h': 178.725, 'l': 176.07, 't': 1709269200000, 'n': 406699}, {'v': 37381520.0, 'vw': 178.5391, 'o': 177.53, 'c': 177.58, 'h': 180.14, 'l': 177.49, 't': 1709528400000, 'n': 443556}, {'v': 37215693.0, 'vw': 174.4671, 'o': 176.93, 'c': 174.12, 'h': 176.93, 'l': 173.303, 't': 1709614800000, 'n': 448859}, {'v': 32090926.0, 'vw': 174.3209, 'o': 175.54, 'c': 173.51, 'h': 176.46, 'l': 173.26, 't': 1709701200000, 'n': 389497}, {'v': 33934783.0, 'vw': 176.4308, 'o': 174.83, 'c': 176.82, 'h': 177.99, 'l': 173.72, 't': 1709787600000, 'n': 379857}, {'v': 37772242.0, 'vw': 176.2118, 'o': 176.44, 'c': 175.35, 'h': 178.785, 'l': 174.33, 't': 1709874000000, 'n': 443160}, {'v': 28484777.0, 'vw': 172.4231, 'o': 174.31, 'c': 171.96, 'h': 174.47, 'l': 171.47, 't': 1710129600000, 'n': 409871}, {'v': 36590204.0, 'vw': 175.3072, 'o': 173.5, 'c': 175.39, 'h': 176.76, 'l': 171.98, 't': 1710216000000, 'n': 416721}, {'v': 30705600.0, 'vw': 176.729, 'o': 175.9, 'c': 176.555, 'h': 177.62, 'l': 175.55, 't': 1710302400000, 'n': 362922}, {'v': 43705840.0, 'vw': 178.4157, 'o': 177.69, 'c': 178.75, 'h': 179.53, 'l': 176.465, 't': 1710388800000, 'n': 461845}, {'v': 71805390.0, 'vw': 175.0471, 'o': 176.64, 'c': 174.42, 'h': 177.93, 'l': 173.9, 't': 1710475200000, 'n': 465349}, {'v': 31251524.0, 'vw': 175.088, 'o': 175.8, 'c': 174.48, 'h': 176.69, 'l': 174.28, 't': 1710734400000, 'n': 358833}, {'v': 26862093.0, 'vw': 175.3683, 'o': 174.215, 'c': 175.9, 'h': 176.09, 'l': 173.52, 't': 1710820800000, 'n': 318060}, {'v': 29947150.0, 'vw': 176.6897, 'o': 176.14, 'c': 178.15, 'h': 178.53, 'l': 174.64, 't': 1710907200000, 'n': 355615}, {'v': 32824320.0, 'vw': 179.3211, 'o': 179.988, 'c': 178.15, 'h': 181.415, 'l': 178.15, 't': 1710993600000, 'n': 377254}, {'v': 27995378.0, 'vw': 178.5495, 'o': 177.752, 'c': 178.87, 'h': 179.255, 'l': 176.75, 't': 1711080000000, 'n': 295011}, {'v': 29815464.0, 'vw': 179.6492, 'o': 178.01, 'c': 179.71, 'h': 180.99, 'l': 177.24, 't': 1711339200000, 'n': 352597}, {'v': 29658982.0, 'vw': 179.1228, 'o': 180.15, 'c': 178.3, 'h': 180.45, 'l': 177.95, 't': 1711425600000, 'n': 326743}, {'v': 32672551.0, 'vw': 179.1032, 'o': 179.88, 'c': 179.83, 'h': 180, 'l': 177.3099, 't': 1711512000000, 'n': 341920}, {'v': 37970288.0, 'vw': 180.4856, 'o': 180.17, 'c': 180.38, 'h': 181.7, 'l': 179.26, 't': 1711598400000, 'n': 364799}, {'v': 29174521.0, 'vw': 180.9175, 'o': 180.79, 'c': 180.97, 'h': 183, 'l': 179.95, 't': 1711944000000, 'n': 370612}, {'v': 32605246.0, 'vw': 180.0752, 'o': 179.07, 'c': 180.69, 'h': 180.79, 'l': 178.3762, 't': 1712030400000, 'n': 355847}, {'v': 31024438.0, 'vw': 182.085, 'o': 179.9, 'c': 182.41, 'h': 182.87, 'l': 179.8, 't': 1712116800000, 'n': 350781}, {'v': 41624261.0, 'vw': 182.5315, 'o': 184, 'c': 180, 'h': 185.1, 'l': 180, 't': 1712203200000, 'n': 465372}, {'v': 42373992.0, 'vw': 184.7021, 'o': 182.38, 'c': 185.07, 'h': 186.27, 'l': 181.97, 't': 1712289600000, 'n': 465500}, {'v': 39221282.0, 'vw': 185.8041, 'o': 186.9, 'c': 185.19, 'h': 187.29, 'l': 184.81, 't': 1712548800000, 'n': 427793}, {'v': 36529846.0, 'vw': 185.5047, 'o': 187.24, 'c': 185.67, 'h': 187.34, 'l': 184.2, 't': 1712635200000, 'n': 400970}, {'v': 35879151.0, 'vw': 185.0344, 'o': 182.765, 'c': 185.95, 'h': 186.2699, 'l': 182.67, 't': 1712721600000, 'n': 448182}, {'v': 40020742.0, 'vw': 187.97, 'o': 186.74, 'c': 189.05, 'h': 189.77, 'l': 185.51, 't': 1712808000000, 'n': 445674}, {'v': 38474349.0, 'vw': 186.5585, 'o': 187.72, 'c': 186.13, 'h': 188.38, 'l': 185.08, 't': 1712894400000, 'n': 420405}, {'v': 45883331.0, 'vw': 185.5439, 'o': 187.425, 'c': 183.62, 'h': 188.69, 'l': 183, 't': 1713153600000, 'n': 507779}, {'v': 32189090.0, 'vw': 183.7052, 'o': 183.27, 'c': 183.32, 'h': 184.83, 'l': 182.26, 't': 1713240000000, 'n': 400832}, {'v': 30588798.0, 'vw': 182.0551, 'o': 184.31, 'c': 181.28, 'h': 184.57, 'l': 179.82, 't': 1713326400000, 'n': 395747}, {'v': 30438610.0, 'vw': 180.2708, 'o': 181.47, 'c': 179.22, 'h': 182.39, 'l': 178.65, 't': 1713412800000, 'n': 383853}, {'v': 55099718.0, 'vw': 175.546, 'o': 178.74, 'c': 174.63, 'h': 179, 'l': 173.44, 't': 1713499200000, 'n': 569799}, {'v': 37276971.0, 'vw': 176.7175, 'o': 176.94, 'c': 177.23, 'h': 178.87, 'l': 174.56, 't': 1713758400000, 'n': 396237}, {'v': 35883580.0, 'vw': 178.5015, 'o': 178.08, 'c': 179.54, 'h': 179.93, 'l': 175.975, 't': 1713844800000, 'n': 379352}, {'v': 32338288.0, 'vw': 177.2697, 'o': 179.94, 'c': 176.59, 'h': 180.323, 'l': 176.18, 't': 1713931200000, 'n': 405260}, {'v': 47859606.0, 'vw': 171.9888, 'o': 169.68, 'c': 173.67, 'h': 173.92, 'l': 166.32, 't': 1714017600000, 'n': 618220}, {'v': 42991451.0, 'vw': 178.9583, 'o': 177.795, 'c': 179.62, 'h': 180.82, 'l': 176.13, 't': 1714104000000, 'n': 478122}, {'v': 53420432.0, 'vw': 180.6596, 'o': 182.75, 'c': 180.96, 'h': 183.53, 'l': 179.39, 't': 1714363200000, 'n': 592772}, {'v': 92358467.0, 'vw': 178.7844, 'o': 181.09, 'c': 175, 'h': 182.99, 'l': 174.8, 't': 1714449600000, 'n': 852770}, {'v': 93365237.0, 'vw': 180.4115, 'o': 181.635, 'c': 179, 'h': 185.15, 'l': 176.56, 't': 1714536000000, 'n': 964449}, {'v': 53548619.0, 'vw': 183.1725, 'o': 180.85, 'c': 184.72, 'h': 185.1, 'l': 179.91, 't': 1714622400000, 'n': 529375}, {'v': 38922939.0, 'vw': 186.4292, 'o': 186.99, 'c': 186.21, 'h': 187.87, 'l': 185.42, 't': 1714708800000, 'n': 413882}, {'v': 33541815.0, 'vw': 187.0004, 'o': 186.28, 'c': 188.7, 'h': 188.745, 'l': 184.8, 't': 1714968000000, 'n': 394601}, {'v': 33118358.0, 'vw': 188.7462, 'o': 188.92, 'c': 188.76, 'h': 189.94, 'l': 187.305, 't': 1715054400000, 'n': 400690}, {'v': 25323433.0, 'vw': 187.6252, 'o': 187.44, 'c': 188, 'h': 188.43, 'l': 186.385, 't': 1715140800000, 'n': 306809}, {'v': 43246564.0, 'vw': 189.9413, 'o': 188.88, 'c': 189.5, 'h': 191.7, 'l': 187.44, 't': 1715227200000, 'n': 460845}, {'v': 33819603.0, 'vw': 188.0401, 'o': 189.16, 'c': 187.48, 'h': 189.892, 'l': 186.93, 't': 1715313600000, 'n': 355958}, {'v': 24513188.0, 'vw': 186.4324, 'o': 188, 'c': 186.57, 'h': 188.31, 'l': 185.36, 't': 1715572800000, 'n': 333222}, {'v': 38512093.0, 'vw': 185.9179, 'o': 183.82, 'c': 187.07, 'h': 187.72, 'l': 183.45, 't': 1715659200000, 'n': 426678}, {'v': 75107139.0, 'vw': 184.7257, 'o': 185.97, 'c': 185.99, 'h': 186.7193, 'l': 182.73, 't': 1715745600000, 'n': 786170}, {'v': 38582942.0, 'vw': 185.2026, 'o': 185.6, 'c': 183.63, 'h': 187.31, 'l': 183.46, 't': 1715832000000, 'n': 411898}, {'v': 32700331.0, 'vw': 184.5338, 'o': 183.76, 'c': 184.7, 'h': 185.3, 'l': 183.35, 't': 1715918400000, 'n': 339388}, {'v': 29911295.0, 'vw': 184.4671, 'o': 184.34, 'c': 183.54, 'h': 186.665, 'l': 183.28, 't': 1716177600000, 'n': 371966}, {'v': 50090936.0, 'vw': 181.8495, 'o': 182.3, 'c': 183.15, 'h': 183.26, 'l': 180.75, 't': 1716264000000, 'n': 515567}, {'v': 27875809.0, 'vw': 183.4607, 'o': 183.88, 'c': 183.13, 'h': 185.22, 'l': 181.9715, 't': 1716350400000, 'n': 344801}, {'v': 32479977.0, 'vw': 182.1607, 'o': 183.66, 'c': 181.05, 'h': 184.76, 'l': 180.08, 't': 1716436800000, 'n': 384702}, {'v': 27048008.0, 'vw': 181.3771, 'o': 181.65, 'c': 180.75, 'h': 182.435, 'l': 180.3, 't': 1716523200000, 'n': 333183}, {'v': 29260373.0, 'vw': 181.1736, 'o': 179.93, 'c': 182.15, 'h': 182.24, 'l': 179.49, 't': 1716868800000, 'n': 401018}, {'v': 31494536.0, 'vw': 182.6171, 'o': 181.7, 'c': 182.02, 'h': 184.08, 'l': 181.55, 't': 1716955200000, 'n': 361201}, {'v': 28549108.0, 'vw': 179.8132, 'o': 181.31, 'c': 179.32, 'h': 181.34, 'l': 178.355, 't': 1717041600000, 'n': 392705}, {'v': 57234811.0, 'vw': 175.6374, 'o': 178.3, 'c': 176.44, 'h': 179.21, 'l': 173.87, 't': 1717128000000, 'n': 614367}]\n"
     ]
    }
   ],
   "source": [
    "print(stock_data_test)\n",
    "# print(len(stock_data_val))\n",
    "# print(len(stock_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d2765ab1-89bd-4f56-8e41-7b0d7c670b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This removes the unnecessary features in the data returned from the api. \n",
    "def clean_stock_data(data):\n",
    "    for day in data:\n",
    "        del day['t'] \n",
    "        del day['v']\n",
    "        del day['n'] \n",
    "        del day['vw']\n",
    "    return data\n",
    "\n",
    "# Assuming you have your splits already defined\n",
    "train_data = clean_stock_data(stock_data_train)\n",
    "val_data = clean_stock_data(stock_data_val)\n",
    "test_data = clean_stock_data(stock_data_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d5a72431-a965-4b97-9717-baa41b78b177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "126\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1aff1893-5aa7-4456-b9dd-0ea9fdcf5f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "126\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScale\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))\n",
    "\n",
    "\n",
    "def normalize_data(data):\n",
    "    # To normalize the data we have to convert the dictionaries into a dataframe, then back into a list of dictionaries\n",
    "    \n",
    "    # Step 1: Convert the list of dictionaries into a dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Step 2: Convert the normalized array back to a DataFrame with the original column names\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    normalized_array = scaler.fit_transform(df) # This converts it into a array\n",
    "    \n",
    "    # Convert the normalized array back to a DataFrame with the original column names\n",
    "    normalized_df = pd.DataFrame(normalized_array, columns=df.columns)\n",
    "    \n",
    "    # Step 3: Convert the DataFrame back to a list of dictionaries\n",
    "    normalized_stock_data = normalized_df.to_dict(orient='records') # This is the new variable containing all of the data.\n",
    "\n",
    "    return normalized_stock_data\n",
    "\n",
    "# Apply everything to the data\n",
    "train_data = normalize_data(train_data)\n",
    "val_data = normalize_data(val_data)\n",
    "test_data = normalize_data(test_data)\n",
    "\n",
    "\n",
    "\n",
    "# print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fe4330-d626-4a6b-bb6f-90f4940451fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0c4bd174-7b0a-4169-8d6f-d8aac0559e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 40, 3)\n",
      "(84,)\n",
      "(86, 40, 3)\n",
      "(86,)\n",
      "(65, 40, 3)\n",
      "(65,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# This is what the model will train on. The remaining of the data is like the y values.\n",
    "def create_sequences_and_targets(data, window_size):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        # Extract 'o', 'h', 'l' for each day excluding 'c'\n",
    "        sequence = [[day['o'], day['h'], day['l']] for day in data[i:i+window_size]]\n",
    "        sequences.append(sequence) # X data\n",
    "        targets.append(data[i+window_size]['c']) # y data\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Set your window size (e.g., 60 days)\n",
    "window_size = 40\n",
    "\n",
    "# Create sequences\n",
    "train_sequences, train_targets = create_sequences_and_targets(train_data, window_size)\n",
    "val_sequences, val_targets = create_sequences_and_targets(val_data, window_size)\n",
    "test_sequences, test_targets = create_sequences_and_targets(test_data, window_size)\n",
    "\n",
    "print(train_sequences.shape)  \n",
    "print(train_targets.shape) \n",
    "\n",
    "print(val_sequences.shape)\n",
    "print(val_targets.shape)\n",
    "\n",
    "print(test_sequences.shape)\n",
    "print(test_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "81806c22-cd73-4fd3-ab83-349493ede6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71644781 0.7489428  0.73469842 0.65768974 0.64411306 0.71778322\n",
      " 0.68506566 0.60961496 0.68595593 0.71188515 0.76073893 0.66436679\n",
      " 0.6657022  0.69730692 0.74738482 0.74738482 0.76340975 0.7821055\n",
      " 0.75072335 0.78477632 0.79701758 0.81014912 0.8039172  0.84219898\n",
      " 0.78855998 0.90140218 0.904073   0.91475629 0.9209882  0.98998442\n",
      " 0.92499444 0.86912976 0.8624527  0.81704874 0.77119964 0.66904073\n",
      " 0.72690852 0.77832183 0.71266414 0.64767416 0.78010238 0.80992655\n",
      " 0.67727576 0.76630314 0.89361229 0.92677498 0.98219452 0.98352994\n",
      " 0.96661473 1.         0.95504118 0.93478745 0.94591587 0.92187848\n",
      " 0.86935233 0.89316715 0.86734921 0.85866904 0.8582239  0.81192967\n",
      " 0.80525262 0.8364122  0.83351881 0.77342533 0.70932562]\n"
     ]
    }
   ],
   "source": [
    "print(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5887650d-7a1a-4494-94cd-b5f7aefbbeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86, 40, 3)\n",
      "(86,)\n"
     ]
    }
   ],
   "source": [
    "# This is to convert the dictionaries into a format to where it could be fed into the model. \n",
    "\n",
    "#transformed_sequences = []\n",
    "\n",
    "# Iterate through the 113 sequences\n",
    "#for sequence in sequences:\n",
    "    #transformed_sequence = []\n",
    "    # Iterate each day in the sequence\n",
    "    #for day in sequence:\n",
    "        # Extract values from the dictionary and create a list for each day\n",
    "        #transformed_day = [day['o'], day['c'], day['h'], day['l']]\n",
    "        #transformed_sequence.append(transformed_day)\n",
    "    #transformed_sequences.append(transformed_sequence)\n",
    "\n",
    "# Convert the list of lists into a numpy array\n",
    "#transformed_sequences = np.array(transformed_sequences)\n",
    "\n",
    "#print(transformed_sequences.shape) #The shape is (113, 40, 4) because there are 113 sequences, with each sequence having 40 days worth of data, and each day had 4 features (open, close, high, low). Each of these are nested into eachother. \n",
    "\n",
    "\n",
    "print(val_sequences.shape)\n",
    "print(val_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fdb8a3bb-b4d1-4205-a16c-69e0e7c420ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 14:19:25.154038: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-14 14:19:25.365813: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-14 14:19:25.740342: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-14 14:19:25.790836: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-14 14:19:26.152132: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-14 14:19:26.394383: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-14 14:19:26.480282: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - ETA: 0s - loss: 0.1221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 14:19:27.722018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-14 14:19:27.786376: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-14 14:19:27.827450: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-14 14:19:27.883394: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 4s 332ms/step - loss: 0.1221 - val_loss: 0.0362\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0326 - val_loss: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hadibishr/miniforge3/envs/stockprediction/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0134 - val_loss: 0.0368\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0098 - val_loss: 0.0349\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0091 - val_loss: 0.0366\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0067 - val_loss: 0.0315\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0074 - val_loss: 0.0310\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0063 - val_loss: 0.0306\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0052 - val_loss: 0.0302\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0049 - val_loss: 0.0307\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0046 - val_loss: 0.0299\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0045 - val_loss: 0.0300\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0046 - val_loss: 0.0294\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0046 - val_loss: 0.0292\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0044 - val_loss: 0.0293\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.0291\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0044 - val_loss: 0.0307\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0058 - val_loss: 0.0300\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0304\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0061 - val_loss: 0.0290\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.0284\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0039 - val_loss: 0.0280\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0039 - val_loss: 0.0279\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0044 - val_loss: 0.0283\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.0278\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0039 - val_loss: 0.0276\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0041 - val_loss: 0.0278\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0051 - val_loss: 0.0272\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0037 - val_loss: 0.0272\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0040 - val_loss: 0.0271\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0041 - val_loss: 0.0273\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0036 - val_loss: 0.0272\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0040 - val_loss: 0.0268\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0039 - val_loss: 0.0267\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0043 - val_loss: 0.0271\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0041 - val_loss: 0.0266\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0037 - val_loss: 0.0264\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0039 - val_loss: 0.0268\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.0264\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0037 - val_loss: 0.0263\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0038 - val_loss: 0.0265\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0036 - val_loss: 0.0262\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0037 - val_loss: 0.0261\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0038 - val_loss: 0.0266\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0038 - val_loss: 0.0271\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0045 - val_loss: 0.0277\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0035 - val_loss: 0.0262\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0034 - val_loss: 0.0267\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0033 - val_loss: 0.0268\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0041 - val_loss: 0.0266\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.0259\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0033 - val_loss: 0.0259\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.0262\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0036 - val_loss: 0.0268\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0036 - val_loss: 0.0279\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0059 - val_loss: 0.0301\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0062 - val_loss: 0.0286\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0040 - val_loss: 0.0264\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0039 - val_loss: 0.0264\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0045 - val_loss: 0.0280\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.0277\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(window_size, 3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=100, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_sequences, train_targets, epochs=500, batch_size=16,\n",
    "                    validation_data=(val_sequences, val_targets), callbacks=[early_stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c8647442-b937-4fbf-85c3-ae831a785a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0098\n",
      "Test Loss: 0.009765306487679482\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(test_sequences, test_targets)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f452d61f-2fdb-4653-bb38-48250e4ba5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start_pred = '2024-06-06'\n",
    "date_end_pred = '2024-08-03'\n",
    "\n",
    "url_pred = f'https://api.polygon.io/v2/aggs/ticker/{symbol}/range/1/day/{date_start_pred}/{date_end_pred}?adjusted=true&sort=asc&apiKey={APIKEY}'\n",
    "\n",
    "response_pred = requests.get(url_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1aec44b0-5d44-4b72-999a-ada38af3f52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "data = response_pred.json()\n",
    "pred_data = data['results']\n",
    "pred_data = clean_stock_data(pred_data)\n",
    "\n",
    "normalized_pred_data = normalize_data(pred_data)\n",
    "\n",
    "print(len(normalized_pred_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5ea45fe5-7358-46dc-aec1-5f22386d0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to the same format as your training data (list of lists)\n",
    "pred_data = [[day['o'], day['h'], day['l']] for day in normalized_pred_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "89b7e72a-d46c-42dd-87dc-54d5e291ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = np.array(pred_data).reshape(1, 40, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "84603b5d-7be7-4ef7-b37e-233d7baa864e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 40, 3)\n"
     ]
    }
   ],
   "source": [
    "print(pred_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a8d28235-71bb-4737-b445-f669e6239f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 14:20:00.976469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-14 14:20:01.048254: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-14 14:20:01.082240: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-14 14:20:01.115119: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x167bb7ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x167bb7ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 492ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a31fcaf9-4343-4c0f-ae16-27a662728400",
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormalized_prediction = scaler.inverse_transform([[0, prediction[0][0], 0, 0]])[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "36806948-964d-411a-8f82-daee7e2443e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Closing Price: 202.5430045235157\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted Closing Price: {unnormalized_prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046b4fe-53bf-4554-b287-f34fc00c7323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
